{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HW 2\n",
    "* Ask the user to supply the mean and standard deviation of a 1D Gaussian\n",
    "\n",
    "\n",
    "* For the given mean and std, draw 1,000,000 random samples from the 1D Gaussian \n",
    "\n",
    "\n",
    "* Build a dataset ùíü with 1,000 histogram bins \n",
    "\n",
    "\n",
    "* Split the dataset into train (90%) and test (10%): ùíü={ùíü_ùë°ùëüùëéùëñùëõ,ùíü_ùë°ùëíùë†ùë° }. Make sure both train and test are IID.\n",
    "\n",
    "\n",
    "* Using pure Python3 and Numpy, build a 3-layer neural networks: \n",
    "\n",
    "\n",
    "* Layers: {1‚àí64‚àíùëÖùëíùêøùëà‚àí64‚àíùëÖùëíùêøùëà‚àí64‚àí1‚àíùë†ùëñùëîùëöùëúùëñùëë}  . Sigmoid is optional.\n",
    "\n",
    "\n",
    "* Initialize the weights using a Gaussian distribution with zero mean and std=0.01\n",
    "\n",
    "\n",
    "* Using pure Python3 and Numpy, implement the backpropagation discussed in this class. Learning rate=0.1. Batch size =1. Loss=MSE.\n",
    "\n",
    "\n",
    "* Train for 20 epochs and evaluate the performance of your network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So first, let us get the mean and standard deviation from the user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Give mean: 0\n",
      "0.0\n",
      "Give standard dev: 1\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "mean = input(\"Give mean: \")\n",
    "mean = float(mean)\n",
    "print(mean)\n",
    "std = input(\"Give standard dev: \")\n",
    "std = float(std)\n",
    "print(std)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example, we get a mean of 0 and standard deviation of 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num of datapoints: 1000000\n",
      "Mean: -0.0005503085198210411\n",
      "Standard Deviation: 1.0000568214672916\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "#Set a random seed so that results are reproducible\n",
    "np.random.seed(24)\n",
    "\n",
    "\n",
    "# Create our 1D Gaussian using our mean and std from user with 1,000,000 datapoints\n",
    "gauss_data = np.random.normal(mean, std, size=1000000)\n",
    "print(\"Num of datapoints:\",len(gauss_data))\n",
    "print(\"Mean:\",gauss_data.mean() )\n",
    "print(\"Standard Deviation:\",gauss_data.std() )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use np.random.normal to create a normal distribution with the given mean and standard deviation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Build a dataset ùíü with 1,000 histogram bins \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# We get the values from our histogram plot so that we know the frequency of each bin\n",
    "# We set bins = 1000 because we only want 1000 samples from our dataset\n",
    "\n",
    "counts, bins, bars = plt.hist(gauss_data, density = True, bins= 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the plot above, we see that the data is truly a normal distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "D_x = bins[:1000] #Values\n",
    "D_y = counts #Frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(D_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(D_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Split the dataset into train (90%) and test (10%): ùíü={ùíü_ùë°ùëüùëéùëñùëõ,ùíü_ùë°ùëíùë†ùë° }. Make sure both train and test are IID.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(D_x, D_y, test_size=0.1, random_state = 12)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that we only used the sklearn library to create our train/test split, since the instructions were to use pure Python and Numpy in implementing the neural network and backpropagation. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to make sure that the test and train splits are IID, so we implement a KS test to check whether this holds true."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KstestResult(statistic=0.06333333333333334, pvalue=0.8454854163038065)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.stats import ks_2samp\n",
    "\n",
    "ks_2samp(X_train, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KstestResult(statistic=0.07111111111111111, pvalue=0.7315282656781205)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ks_2samp(y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since our p-values are high (> 0.05), it is probable that the D_test and D_train are IID"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Using pure Python3 and Numpy, build a 3-layer neural networks: \n",
    "\n",
    "\n",
    "* Layers: {1‚àí64‚àíùëÖùëíùêøùëà‚àí64‚àíùëÖùëíùêøùëà‚àí64‚àí1‚àíùë†ùëñùëîùëöùëúùëñùëë}  . Sigmoid is optional.\n",
    "\n",
    "\n",
    "* Initialize the weights using a Gaussian distribution with zero mean and std=0.01\n",
    "\n",
    "\n",
    "* Using pure Python3 and Numpy, implement the backpropagation discussed in this class. Learning rate=0.1. Batch size =1. Loss=MSE."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first thing that we will do is to create our activation functions. These activation functions specifically, are the ReLU and the sigmoid functions. Activation functions add non-linearity to our neural networks, else they would just be cominbations of linear functions. Note that we also need to prepare their derivatives for implementation of the forward propagation and backpropagation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image info](https://www.researchgate.net/profile/Knut_Kvaal/publication/239269767/figure/fig2/AS:643520205430784@1530438581076/An-illustration-of-the-signal-processing-in-a-sigmoid-function.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image info](https://miro.medium.com/max/1000/1*3JUMOqugWKB2SDra6x6v0A.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(Z):\n",
    "    return 1 / (1+ np.exp(-Z))\n",
    "\n",
    "def sigmoid_prime(dA, Z):\n",
    "    sig = sigmoid(Z)\n",
    "    return dA * sig * (1 - sig)\n",
    "\n",
    "def relu(Z):\n",
    "    return np.maximum(Z, 0)\n",
    "\n",
    "def relu_prime(dA, Z):\n",
    "    dZ = np.array(dA, copy = True)\n",
    "    dZ[Z <= 0] = 0;\n",
    "    return dZ;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will implement our weight initialization. It is important to initalize our weights so that the outputs from our activation layers that we implemented above do not explode our vanish during the forward pass a deep neural network. If either occurs, then loss gradients will be to small or too large for the backpropagation. Thus, it will take longer to converge or perhaps never converge at all."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_layers(nn_architecture, seed = 24):\n",
    "    # We set our random seed for reproducibility\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    \n",
    "    number_of_layers = len(nn_architecture)\n",
    "    params_values = {}\n",
    "    \n",
    "    # iteration over network layers\n",
    "    for idx, layer in enumerate(nn_architecture):\n",
    "        layer_idx = idx + 1\n",
    "        \n",
    "        # extracting the number of units in layers\n",
    "        layer_input_size = layer[\"input_dim\"]\n",
    "        layer_output_size = layer[\"output_dim\"]\n",
    "        \n",
    "# Initialize the weights using a Gaussian distribution with zero mean and std=0.01\n",
    "        params_values['W' + str(layer_idx)] = np.random.normal(0, 0.01, size = (layer_output_size, layer_input_size) )\n",
    "        params_values['b' + str(layer_idx)] = np.zeros((layer_output_size, 1) ) \n",
    "        \n",
    "    return params_values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we can implement our backpropagation, we need to first implement our forward pass. Our input data is fed forward through the network. Each hidden layer accepts this input data, processes it according to the activation function and passes it on to the next successive layer. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image info](https://miro.medium.com/max/596/1*tp73P0isrrfpj8RG-5aH6w.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:5: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "<>:7: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "<>:5: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "<>:7: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "<ipython-input-12-dda81e0202a9>:5: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  if activation is \"relu\":\n",
      "<ipython-input-12-dda81e0202a9>:7: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  elif activation is \"sigmoid\":\n"
     ]
    }
   ],
   "source": [
    "def single_layer_forward_propagation(A_prev, W_curr, b_curr, activation):\n",
    "    Z_curr = np.dot(W_curr, A_prev) + b_curr\n",
    "    \n",
    "    # Pick which implemented activation function to use\n",
    "    if activation is \"relu\":\n",
    "        activation_func = relu\n",
    "    elif activation is \"sigmoid\":\n",
    "        activation_func = sigmoid\n",
    "\n",
    "    return activation_func(Z_curr), Z_curr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def full_forward_propagation(X, params_values, nn_architecture):\n",
    "    memory = {}\n",
    "    # Layer 0‚Ää\n",
    "    A_curr = X\n",
    "    \n",
    "    # iteration over network layers\n",
    "    for idx, layer in enumerate(nn_architecture):\n",
    "        layer_idx = idx + 1\n",
    "        # transfer the activation from the previous iteration\n",
    "        A_prev = A_curr\n",
    "        \n",
    "        activ_function_curr = layer[\"activation\"] #Activation function for current layer\n",
    "        \n",
    "        W_curr = params_values[\"W\" + str(layer_idx)] #Weights for current layer\n",
    "        b_curr = params_values[\"b\" + str(layer_idx)] #Biases for current layer\n",
    "        \n",
    "        #Application of function above given the current weights, biases, and activation function\n",
    "        A_curr, Z_curr = single_layer_forward_propagation(A_prev, W_curr, b_curr, activ_function_curr)\n",
    "        \n",
    "        \n",
    "        # saving calculated values in the memory\n",
    "        memory[\"A\" + str(idx)] = A_prev\n",
    "        memory[\"Z\" + str(layer_idx)] = Z_curr\n",
    "       \n",
    "    return A_curr, memory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Using pure Python3 and Numpy, implement the backpropagation discussed in this class. Learning rate=0.1. Batch size =1. Loss=MSE."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First let's create our loss function which should be MSE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The loss function is what gives us a sense of how good our model is. It is used to evaluate our model's performance. MSE stands for Mean Squared Error, and it is calculated as the average of the squared differences between the predicted and actual values. Thus, its output is always a positive value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image info](https://i.imgur.com/vB3UAiH.jpeg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(pred, actual):\n",
    "    \"\"\"MSE loss function\"\"\"\n",
    "    return np.mean((actual - pred)**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we implement our backpropagation. Backpropagation is a way of propagating the total loss back into the neural network to calculate how much of the loss each node is responsible for. This way, each node can update its weights in such a way to minimize the overall loss of the network. It does this by computing for the gradient of the loss function with respect to the weights of the network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image info](https://images.deepai.org/glossary-terms/73eec54be08746f6b546a874580b8673/backpropagation.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:5: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "<>:7: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "<>:5: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "<>:7: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "<ipython-input-15-3630d76793d4>:5: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  if activation is \"relu\":\n",
      "<ipython-input-15-3630d76793d4>:7: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  elif activation is \"sigmoid\":\n"
     ]
    }
   ],
   "source": [
    "def single_layer_backward_propagation(dA_curr, W_curr, b_curr, Z_curr, A_prev, activation):\n",
    "    m = A_prev.shape[1]\n",
    "    \n",
    "    # Picking activation function by using its derivative\n",
    "    if activation is \"relu\":\n",
    "        backward_activation_func = relu_prime\n",
    "    elif activation is \"sigmoid\":\n",
    "        backward_activation_func = sigmoid_prime\n",
    "\n",
    "    # calculation of the activation function derivative\n",
    "    dZ_curr = backward_activation_func(dA_curr, Z_curr)\n",
    "    \n",
    "    # derivative of the weights\n",
    "    dW_curr = np.dot(dZ_curr, A_prev.T) \n",
    "    # derivative of the bias\n",
    "    db_curr = np.sum(dZ_curr, axis=1, keepdims=True) \n",
    "    # derivative of the matrix A_prev\n",
    "    dA_prev = np.dot(W_curr.T, dZ_curr)\n",
    "\n",
    "    return dA_prev, dW_curr, db_curr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def full_backward_propagation(Y_hat, Y, memory, params_values, nn_architecture):\n",
    "    grads_values = {}\n",
    "    \n",
    "    # number of examples\n",
    "    m = Y.shape[1]\n",
    "    # a hack ensuring the same shape of the prediction vector and labels vector\n",
    "    Y = Y.reshape(Y_hat.shape)\n",
    "    \n",
    "    # initiation of gradient descent algorithm\n",
    "    # since we're using MSE\n",
    "    dA_prev = (Y_hat - Y) * 2\n",
    "    \n",
    "    for layer_idx_prev, layer in reversed(list(enumerate(nn_architecture))):\n",
    "        layer_idx_curr = layer_idx_prev + 1\n",
    "        \n",
    "        activ_function_curr = layer[\"activation\"]\n",
    "        \n",
    "        dA_curr = dA_prev\n",
    "        \n",
    "        A_prev = memory[\"A\" + str(layer_idx_prev)]\n",
    "        Z_curr = memory[\"Z\" + str(layer_idx_curr)]\n",
    "        \n",
    "        W_curr = params_values[\"W\" + str(layer_idx_curr)]\n",
    "        b_curr = params_values[\"b\" + str(layer_idx_curr)]\n",
    "        \n",
    "        dA_prev, dW_curr, db_curr = single_layer_backward_propagation(\n",
    "            dA_curr, W_curr, b_curr, Z_curr, A_prev, activ_function_curr)\n",
    "        \n",
    "        grads_values[\"dW\" + str(layer_idx_curr)] = dW_curr\n",
    "        grads_values[\"db\" + str(layer_idx_curr)] = db_curr\n",
    "    \n",
    "    return grads_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next part is simply updating our weights and biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update(params_values, grads_values, nn_architecture, learning_rate):\n",
    "\n",
    "    # iteration over network layers\n",
    "    for layer_idx, layer in enumerate(nn_architecture, 1):\n",
    "        params_values[\"W\" + str(layer_idx)] -= learning_rate * grads_values[\"dW\" + str(layer_idx)]        \n",
    "        params_values[\"b\" + str(layer_idx)] -= learning_rate * grads_values[\"db\" + str(layer_idx)]\n",
    "\n",
    "    return params_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly, we create our training function to apply all of the functions we've implemented so far. The training process will look similar to the picture below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "![image info](https://www.researchgate.net/publication/327870314/figure/fig1/AS:674797562363914@1537895684936/Flow-chart-of-the-neural-network-training-process.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(X, Y, nn_architecture, epochs, learning_rate, verbose=False, callback=None):\n",
    "    # initiation of neural net parameters\n",
    "    params_values = init_layers(nn_architecture)\n",
    "    # initiation of lists storing the history \n",
    "    # of metrics calculated during the learning process \n",
    "    cost_history = []\n",
    "    \n",
    "    # performing calculations for subsequent iterations\n",
    "    for num in range(epochs):\n",
    "        # step forward\n",
    "        for i in range(len(X)): #So that batch size = 1\n",
    "            Y_hat, cashe = full_forward_propagation(X[:, i:i+1], params_values, nn_architecture)\n",
    "\n",
    "            # calculating metrics and saving them in history\n",
    "            cost = loss(Y_hat, Y[:,i:i+1])\n",
    "            cost_history.append(cost)\n",
    "\n",
    "\n",
    "            # step backward - calculating gradient\n",
    "            grads_values = full_backward_propagation(Y_hat, Y[:,i:i+1], cashe, params_values, nn_architecture)\n",
    "            # updating model state\n",
    "            params_values = update(params_values, grads_values, nn_architecture, learning_rate)\n",
    "        if(num % 1 == 0):\n",
    "            print(\"Iteration: {:05} - cost: {:.8f}\".format(num, cost))\n",
    "            if(callback is not None):\n",
    "                callback(i, params_values)\n",
    "            \n",
    "    return params_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Based on instructions\n",
    "nn_archi = [\n",
    "    {\"input_dim\": 1, \"output_dim\": 64, \"activation\": \"relu\"},\n",
    "    {\"input_dim\": 64, \"output_dim\": 64, \"activation\": \"relu\"},\n",
    "    {\"input_dim\": 64, \"output_dim\": 1, \"activation\": \"sigmoid\"}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just to fix the dimensions\n",
    "\n",
    "X_train = X_train.reshape((1, 900))\n",
    "y_train = y_train.reshape((1, 900))\n",
    "\n",
    "X_test = X_test.reshape((1, 100))\n",
    "y_test = y_test.reshape((1, 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 00000 - cost: 0.24968170\n",
      "Iteration: 00001 - cost: 0.24346060\n",
      "Iteration: 00002 - cost: 0.23739881\n",
      "Iteration: 00003 - cost: 0.23149434\n",
      "Iteration: 00004 - cost: 0.22574877\n",
      "Iteration: 00005 - cost: 0.22015880\n",
      "Iteration: 00006 - cost: 0.21472249\n",
      "Iteration: 00007 - cost: 0.20943770\n",
      "Iteration: 00008 - cost: 0.20430325\n",
      "Iteration: 00009 - cost: 0.19931599\n",
      "Iteration: 00010 - cost: 0.19447282\n",
      "Iteration: 00011 - cost: 0.18977073\n",
      "Iteration: 00012 - cost: 0.18520682\n",
      "Iteration: 00013 - cost: 0.18077816\n",
      "Iteration: 00014 - cost: 0.17648166\n",
      "Iteration: 00015 - cost: 0.17231399\n",
      "Iteration: 00016 - cost: 0.16827193\n",
      "Iteration: 00017 - cost: 0.16435216\n",
      "Iteration: 00018 - cost: 0.16055140\n",
      "Iteration: 00019 - cost: 0.15686632\n"
     ]
    }
   ],
   "source": [
    "# Based on given specs\n",
    "weights = train(X_train, y_train, nn_archi, epochs=20, learning_rate=0.1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's try to evaluate how our model would perform on its unseen data, which is our Test data split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We do this by running our full forward propagation on our test dataset and storing its predictions\n",
    "test_pred, mem = full_forward_propagation(X_test, weights, nn_archi)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 100)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We reshape for plotting purposes\n",
    "X_test = X_test.reshape((100, 1))\n",
    "y_test = y_test.reshape((100, 1))\n",
    "\n",
    "test_pred = test_pred.reshape((100, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 1)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(X_test, y_test, color = 'blue', label = 'Actual')\n",
    "plt.scatter(X_test, test_pred, color = 'red', label = 'Predictions')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The plot above shows how our model runs on the test data. As you can see it doesn't perform very well yet. However, tweaking our model can result in massive boosts to its performance. For example, changing the std at initialization from 0.01 to 0.3 results in a much better model. We can also try testing out different learning rates to get better results. Another thing we can do is to run more epochs. Since we're only running 20 epochs, the model actually trains very quickly so it might be a good idea to have a trade-off of more time spent training, for a better performing model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next cell is just to test out changing our initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_layers(nn_architecture, seed = 24):\n",
    "    # We set our random seed for reproducibility\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    \n",
    "    number_of_layers = len(nn_architecture)\n",
    "    params_values = {}\n",
    "    \n",
    "    # iteration over network layers\n",
    "    for idx, layer in enumerate(nn_architecture):\n",
    "        layer_idx = idx + 1\n",
    "        \n",
    "        # extracting the number of units in layers\n",
    "        layer_input_size = layer[\"input_dim\"]\n",
    "        layer_output_size = layer[\"output_dim\"]\n",
    "        \n",
    "# Initialize the weights using a Gaussian distribution with zero mean and std=0.01\n",
    "        params_values['W' + str(layer_idx)] = np.random.normal(0, 0.3, size = (layer_output_size, layer_input_size) )\n",
    "        params_values['b' + str(layer_idx)] = np.zeros((layer_output_size, 1) ) \n",
    "        \n",
    "    return params_values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 00000 - cost: 0.04829806\n",
      "Iteration: 00001 - cost: 0.00029748\n",
      "Iteration: 00002 - cost: 0.00028494\n",
      "Iteration: 00003 - cost: 0.00027341\n",
      "Iteration: 00004 - cost: 0.00026276\n",
      "Iteration: 00005 - cost: 0.00025290\n",
      "Iteration: 00006 - cost: 0.00024375\n",
      "Iteration: 00007 - cost: 0.00023522\n",
      "Iteration: 00008 - cost: 0.00022726\n",
      "Iteration: 00009 - cost: 0.00021982\n",
      "Iteration: 00010 - cost: 0.00021283\n",
      "Iteration: 00011 - cost: 0.00020628\n",
      "Iteration: 00012 - cost: 0.00020011\n",
      "Iteration: 00013 - cost: 0.00019429\n",
      "Iteration: 00014 - cost: 0.00018879\n",
      "Iteration: 00015 - cost: 0.00018359\n",
      "Iteration: 00016 - cost: 0.00017867\n",
      "Iteration: 00017 - cost: 0.00017400\n",
      "Iteration: 00018 - cost: 0.00016956\n",
      "Iteration: 00019 - cost: 0.00016534\n"
     ]
    }
   ],
   "source": [
    "# Just to fix the dimensions\n",
    "\n",
    "X_train = X_train.reshape((1, 900))\n",
    "y_train = y_train.reshape((1, 900))\n",
    "\n",
    "X_test = X_test.reshape((1, 100))\n",
    "y_test = y_test.reshape((1, 100))\n",
    "\n",
    "# Based on given specs\n",
    "weights = train(X_train, y_train, nn_archi, epochs=20, learning_rate=0.1)\n",
    "\n",
    "# We do this by running our full forward propagation on our test dataset and storing its predictions\n",
    "test_pred, mem = full_forward_propagation(X_test, weights, nn_archi)\n",
    "\n",
    "# We reshape for plotting purposes\n",
    "X_test = X_test.reshape((100, 1))\n",
    "y_test = y_test.reshape((100, 1))\n",
    "\n",
    "test_pred = test_pred.reshape((100, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(X_test, y_test, color = 'blue', label = 'Actual')\n",
    "plt.scatter(X_test, test_pred, color = 'red', label = 'Predictions')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As shown by the plot above, initialization is very crucial to how the model will perform. Even though we used the same number of epochs, the performance was much better."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References:\n",
    "- https://github.com/SkalskiP/ILearnDeepLearning.py/blob/master/01_mysteries_of_neural_networks/03_numpy_neural_net/Numpy%20deep%20neural%20network.ipynb (Main Source of code)\n",
    "- https://www.freecodecamp.org/news/building-a-3-layer-neural-network-from-scratch-99239c4af5d3/\n",
    "- https://towardsdatascience.com/weight-initialization-in-neural-networks-a-journey-from-the-basics-to-kaiming-954fb9b47c79\n",
    "- https://towardsdatascience.com/forward-propagation-in-neural-networks-simplified-math-and-code-version-bbcfef6f9250\n",
    "- https://machinelearningmastery.com/loss-and-loss-functions-for-training-deep-learning-neural-networks/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
